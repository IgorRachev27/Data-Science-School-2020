{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "gradient_methods.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjKtQUpRWoga"
      },
      "source": [
        "# Градиентные методы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuyTjl0zWogd"
      },
      "source": [
        "## Функция $f(x) = x_1^2 +x_2^2+x_1+x_2$, точка $x^{(0)} = (0, 0)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vswd8APwWogd"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQtCCCMZWoge"
      },
      "source": [
        "def f(x):\n",
        "    return x[0]**2+x[1]**2+x[0]+x[1]\n",
        "    \n",
        "def grad_f(x):\n",
        "    return np.array([2*x[0]+1, 2*x[1]+1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOpJXBrCWoge"
      },
      "source": [
        "### Градиентный спуск с постоянным шагом"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL-Z3B2OWogf"
      },
      "source": [
        "def grad_descent_const_step(x = np.array([0, 0]), alpha = 0.001, epsilon = 0.05):\n",
        "    grad = grad_f(x)\n",
        "    n = 0\n",
        "    check = 0\n",
        "    while (np.linalg.norm(grad) > epsilon) or (check < 3):\n",
        "        x = x - alpha*grad\n",
        "        grad = grad_f(x)\n",
        "        n+=1\n",
        "        if (np.linalg.norm(grad) <= epsilon): check +=1\n",
        "    print(\"Градиентный спуст с постоянным шагом выполнил {} шагов\".format(n))\n",
        "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mJCpof0Wogf",
        "outputId": "7dd59c88-3ae3-4c04-a2d4-469ceaa8719e"
      },
      "source": [
        "x = grad_descent_const_step(alpha = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Градиентный спуст с постоянным шагом выполнил 17 шагов\n",
            "Точка с координатами х1 = -0.48874100093157374, x2 = -0.48874100093157374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLdOUr3yWogg"
      },
      "source": [
        "### Градиентный спуск с заранее заданным шагом"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nk4mmkLWogg"
      },
      "source": [
        "def grad_descent_series(x = np.array([0, 0]), epsilon = 0.05):\n",
        "    grad = grad_f(x)\n",
        "    n = 0\n",
        "    k = 1 \n",
        "    check = 0\n",
        "    while np.linalg.norm(grad) > epsilon or check < 3:\n",
        "        x = x - (1/k)*grad\n",
        "        grad = grad_f(x)\n",
        "        k+=1\n",
        "        n+=1\n",
        "        if (np.linalg.norm(grad) <= epsilon): check +=1\n",
        "    print(\"Градиентный спуст с заранее заданным шагом выполнил {} шагов\".format(n))\n",
        "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eqKYl6BWogh",
        "outputId": "bc1d5852-c7a6-423c-cec4-831be13deb11"
      },
      "source": [
        "a = grad_descent_series()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Градиентный спуст с заранее заданным шагом выполнил 4 шагов\n",
            "Точка с координатами х1 = -0.5, x2 = -0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPnPhYeiWogh"
      },
      "source": [
        "### Градиентный спуск с дроблением шага"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWZyREzuWogh"
      },
      "source": [
        "def grad_descent_step_splitting(x = np.array([0, 0]), alpha = 1, epsilon = 0.05, ksi = 0.5, lambda_d = 0.35):\n",
        "    grad = grad_f(x)\n",
        "    n = 0\n",
        "    n_alpha = 0\n",
        "    alpha_k = alpha\n",
        "    x_k0 = x\n",
        "    check = 0\n",
        "    while np.linalg.norm(grad) > epsilon or check < 3:\n",
        "        grad = grad_f(x_k0)\n",
        "        x_k1 = x_k0 - alpha_k*grad\n",
        "        while f(x_k1) - f(x_k0) > - alpha_k * ksi * (np.linalg.norm(grad)**2):\n",
        "            alpha_k *= lambda_d\n",
        "            x_k1 = x_k0 - alpha_k*grad\n",
        "            n_alpha+=1\n",
        "        x_k0 = x_k0 - alpha_k*grad\n",
        "        alpha_k = alpha\n",
        "        n+=1\n",
        "        if (np.linalg.norm(grad) <= epsilon): check +=1\n",
        "    x = x_k0\n",
        "    print(\"Градиентный спуст с дроблением шага выполнил {} шагов\".format(n))\n",
        "    print(\"Выполнено {} итераций дробления шага\".format(n_alpha))\n",
        "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGqi8XiiWogi",
        "outputId": "2ccde5b2-db53-480c-d215-436990c8e522"
      },
      "source": [
        "a = grad_descent_step_splitting()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Градиентный спуст с дроблением шага выполнил 6 шагов\n",
            "Выполнено 6 итераций дробления шага\n",
            "Точка с координатами х1 = -0.4996355, x2 = -0.4996355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igHjlip2Wogi"
      },
      "source": [
        "### Метод наискорейшего градиентного спуска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-2hvLy4Wogj"
      },
      "source": [
        "a, b, eps = 0.0001, 0.9999,  0.005\n",
        "def passive_search(x, grad, a = a, b = b, eps = eps):\n",
        "    \n",
        "    n = round((b-a)/eps)+1\n",
        "    x_s = [a+i*eps for i in range(n)]\n",
        "    y_s = [f(x-i*grad) for i in x_s]\n",
        "    res = y_s.index(min(y_s))\n",
        "    return x_s[res]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lK4H_vaWogj"
      },
      "source": [
        "def grad_descent_series(x = np.array([0, 0]), epsilon = 0.05):\n",
        "    grad = grad_f(x)\n",
        "    n = 0\n",
        "    check = 0\n",
        "    while np.linalg.norm(grad) > epsilon or check < 3:\n",
        "        alp = passive_search(x, grad)\n",
        "        x = x - alp*grad\n",
        "        grad = grad_f(x)\n",
        "        n+=1\n",
        "        if (np.linalg.norm(grad) <= epsilon): check +=1\n",
        "    print(\"Метод наискорейшего градиентного спуска выполнил {} шагов\".format(n))\n",
        "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVjicGsyWogj",
        "outputId": "040b4de6-3a80-4231-9d61-5cef0e7efe88"
      },
      "source": [
        "a = grad_descent_series()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метод наискорейшего градиентного спуска выполнил 3 шагов\n",
            "Точка с координатами х1 = -0.499999996404, x2 = -0.499999996404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjMjhT7DWyLH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}